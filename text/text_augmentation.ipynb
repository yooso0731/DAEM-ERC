{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8201291",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\DDECC\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\user\\anaconda3\\envs\\DDECC\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n",
      "C:\\Users\\user\\anaconda3\\envs\\DDECC\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\user\\anaconda3\\envs\\DDECC\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "# from gensim.models import fasttext\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchmetrics import F1Score\n",
    "\n",
    "import gensim\n",
    "from gensim.models import fasttext\n",
    "\n",
    "ft_path = '.' # fast text가 저장된 경로\n",
    "ft_model = gensim.models.fasttext.load_facebook_model( ft_path + '/wiki.ko.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eb5251",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84eb12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>sess</th>\n",
       "      <th>script</th>\n",
       "      <th>seconds</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_script01_User002M_001</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>8.059001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_script01_User002M_002</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>11.697002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_script01_User002M_003</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>8.223999</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess01_script01_User002M_004</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>11.411998</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess01_script01_User001F_001</td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>2.086000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>Sess40_script06_User079F_043</td>\n",
       "      <td>40</td>\n",
       "      <td>06</td>\n",
       "      <td>5.493020</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>Sess40_script06_User079F_044</td>\n",
       "      <td>40</td>\n",
       "      <td>06</td>\n",
       "      <td>2.655000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>Sess40_script06_User079F_045</td>\n",
       "      <td>40</td>\n",
       "      <td>06</td>\n",
       "      <td>6.573000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>Sess40_script06_User079F_046</td>\n",
       "      <td>40</td>\n",
       "      <td>06</td>\n",
       "      <td>2.692000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10139</th>\n",
       "      <td>Sess40_script06_User079F_047</td>\n",
       "      <td>40</td>\n",
       "      <td>06</td>\n",
       "      <td>2.244000</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10140 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         segment_id  sess script    seconds  emotion  \\\n",
       "0      Sess01_script01_User002M_001     1     01   8.059001  neutral   \n",
       "1      Sess01_script01_User002M_002     1     01  11.697002  neutral   \n",
       "2      Sess01_script01_User002M_003     1     01   8.223999  neutral   \n",
       "3      Sess01_script01_User002M_004     1     01  11.411998  neutral   \n",
       "4      Sess01_script01_User001F_001     1     01   2.086000  neutral   \n",
       "...                             ...   ...    ...        ...      ...   \n",
       "10135  Sess40_script06_User079F_043    40     06   5.493020  neutral   \n",
       "10136  Sess40_script06_User079F_044    40     06   2.655000  neutral   \n",
       "10137  Sess40_script06_User079F_045    40     06   6.573000  neutral   \n",
       "10138  Sess40_script06_User079F_046    40     06   2.692000  neutral   \n",
       "10139  Sess40_script06_User079F_047    40     06   2.244000  neutral   \n",
       "\n",
       "       emotion_id  \n",
       "0               4  \n",
       "1               4  \n",
       "2               4  \n",
       "3               4  \n",
       "4               4  \n",
       "...           ...  \n",
       "10135           4  \n",
       "10136           4  \n",
       "10137           4  \n",
       "10138           4  \n",
       "10139           4  \n",
       "\n",
       "[10140 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './ETRI_ERC/dataset/KEMDy20_v1_1/new/text'\n",
    "\n",
    "# 저장한 데이터 토큰 피클 파일 불러오기\n",
    "with open(path + '/token_NonNP.pkl', 'rb') as f:\n",
    "    text_data = pickle.load(f)\n",
    "\n",
    "text_data['token_len'] = [len(x) for x in text_data['token']]\n",
    "\n",
    "# 다중 레이블 처리한 훈련 데이터셋 가져오기\n",
    "with open(path+'/train_origin.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# 다중 레이블 처리한 테스트 데이터셋 가져오기\n",
    "with open(path+'/test_origin.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d58eae",
   "metadata": {},
   "source": [
    "## 필요 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbd3c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 컬럼만 남겨두기\n",
    "train_data = train_data.drop(['seconds', 'sess', 'script'], axis=1)\n",
    "test_data = test_data.drop(['seconds', 'sess', 'script'], axis=1)\n",
    "\n",
    "# 텍스트에서 필요한 컬럼만 남겨두기 및 컬럼 이름 맞추기\n",
    "text_data = text_data[['segment_id', 'token', 'token_len']]\n",
    "#text_data = text_data.rename(columns={'Segment ID':'segment_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c434ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 및 테스트 데이터에 텍스트 데이터 붙이기\n",
    "train = pd.merge(train_data, text_data, how='left', on=['segment_id'])\n",
    "test = pd.merge(test_data, text_data, how='left', on=['segment_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66bf7dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sess01_script01_User002M_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[는, 어, 어머니, 엄마, 가, 이제, 생일, 때, 마다, 이제, 미역국, 도, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sess01_script01_User002M_002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[전, 에, 도, 말, 했, 지만, 그래서, 미역국, 이랑, 볶음, 김치, 막, 해...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sess01_script01_User002M_003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[어, 응, 되게, 엄, 집, 앞, 에, 그, 조그만, 한, 가게, 로, 있, 었,...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sess01_script01_User002M_004</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[서, 엄마, 랑, 둘, 이, 생일, 파티, 그냥, 간단, 하, 게, 하, 는, 경...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess01_script01_User001F_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[아, 친구, 들, 도]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sess01_script01_User002M_005</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[응, 응, 그래서, 생일, 때, 그렇, 게, 했, 던, 경험, 이, 있, 는데, ...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sess01_script01_User002M_006</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[그래서, 이제, 막, 지역, 돌아다니, 면서, 캔, 모아, 빙수, 있, 는, 가게...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sess01_script01_User002M_007</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "      <td>[어, 그래서, 그런, 가게, 들, 갈, 때, 면, 맨날, 엄마, 생각, 이, 되게...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sess01_script01_User002M_008</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "      <td>[그래서, 일부러, 보이, 면, 일부러, 가, 기, 도, 해]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sess01_script01_User002M_009</td>\n",
       "      <td>happy</td>\n",
       "      <td>3</td>\n",
       "      <td>[그때, 먹, 었, 던, 빙수, 맛, 이, 그대로, 인데, 되게, 맛있, 었, 거든]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     segment_id  emotion  emotion_id  \\\n",
       "0  Sess01_script01_User002M_001  neutral           4   \n",
       "1  Sess01_script01_User002M_002  neutral           4   \n",
       "2  Sess01_script01_User002M_003  neutral           4   \n",
       "3  Sess01_script01_User002M_004  neutral           4   \n",
       "4  Sess01_script01_User001F_001  neutral           4   \n",
       "5  Sess01_script01_User002M_005  neutral           4   \n",
       "6  Sess01_script01_User002M_006  neutral           4   \n",
       "7  Sess01_script01_User002M_007    happy           3   \n",
       "8  Sess01_script01_User002M_008    happy           3   \n",
       "9  Sess01_script01_User002M_009    happy           3   \n",
       "\n",
       "                                               token  token_len  \n",
       "0  [는, 어, 어머니, 엄마, 가, 이제, 생일, 때, 마다, 이제, 미역국, 도, ...         20  \n",
       "1  [전, 에, 도, 말, 했, 지만, 그래서, 미역국, 이랑, 볶음, 김치, 막, 해...         41  \n",
       "2  [어, 응, 되게, 엄, 집, 앞, 에, 그, 조그만, 한, 가게, 로, 있, 었,...         24  \n",
       "3  [서, 엄마, 랑, 둘, 이, 생일, 파티, 그냥, 간단, 하, 게, 하, 는, 경...         43  \n",
       "4                                      [아, 친구, 들, 도]          4  \n",
       "5  [응, 응, 그래서, 생일, 때, 그렇, 게, 했, 던, 경험, 이, 있, 는데, ...         36  \n",
       "6  [그래서, 이제, 막, 지역, 돌아다니, 면서, 캔, 모아, 빙수, 있, 는, 가게...         23  \n",
       "7  [어, 그래서, 그런, 가게, 들, 갈, 때, 면, 맨날, 엄마, 생각, 이, 되게...         16  \n",
       "8                 [그래서, 일부러, 보이, 면, 일부러, 가, 기, 도, 해]          9  \n",
       "9    [그때, 먹, 었, 던, 빙수, 맛, 이, 그대로, 인데, 되게, 맛있, 었, 거든]         13  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9227901",
   "metadata": {},
   "source": [
    "## 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30eeac5d",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1680934646775,
     "user": {
      "displayName": "이한별",
      "userId": "12004192522894525506"
     },
     "user_tz": -540
    },
    "id": "30eeac5d"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "# hyperparameter\n",
    "n_a = 0.3 # 문장 내에서 변환할 단어의 비율\n",
    "del_p = 0.2 # 문장 내에서 단어를 삭제할 확률\n",
    "top_sim = 1 # 동의어 대체에 사용할 fasttext의 유사 단어 개수\n",
    "\n",
    "# 랜덤한 단어를 선택하여 랜덤한 동의어로 변환\n",
    "def SR(tokens, a):\n",
    "    num_modify = int(len(tokens)*a) # 변환할 단어의 개수\n",
    "    modify_idx_list = list(range(0, len(tokens)))\n",
    "    random.shuffle(modify_idx_list)\n",
    "    modify_idx_list = modify_idx_list[:num_modify] # 변환할 토큰의 인덱스\n",
    "    \n",
    "    for mod_idx in modify_idx_list:\n",
    "        rand_rank = random.randrange(0, top_sim) # fasttext의 상위 5개 동의어 중 하나로 변환 \n",
    "        # 현재 단어와 가장 유사한 단어를 가져옴\n",
    "        synonym = ft_model.wv.similar_by_word(tokens[mod_idx], topn=top_sim)[rand_rank][0]\n",
    "        tokens[mod_idx] = synonym\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# 랜덤한 단어를 선택해서 랜덤한 동의어로 변환한 후 랜덤한 위치에 넣음\n",
    "def RI(tokens, a):\n",
    "    num_modify = int(len(tokens)*a) # 변환할 단어의 개수\n",
    "    \n",
    "    for i in range(num_modify):\n",
    "        mod_idx = random.randrange(0, len(tokens))\n",
    "        rand_rank = random.randrange(0, top_sim)\n",
    "        \n",
    "        # 현재 단어와 가장 유사한 단어를 가져옴\n",
    "        synonym = ft_model.wv.similar_by_word(tokens[mod_idx], topn=top_sim)[rand_rank][0]\n",
    "        tokens[mod_idx] = synonym\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "# 랜덤한 단어 두 개를 뽑아 서로의 위치를 바꿈\n",
    "def RS(tokens, a):\n",
    "    num_modify = int(len(tokens)*a) # 변환할 단어의 개수\n",
    "    \n",
    "    for i in range(num_modify):\n",
    "        # 임의의 두 개의 단어 뽑음\n",
    "        modify_idx_list = list(range(0, len(tokens)))\n",
    "        random.shuffle(modify_idx_list)\n",
    "        a,b = modify_idx_list[:2]\n",
    "        \n",
    "        # 서로의 위치를 바꿈\n",
    "        tokens[a], tokens[b] = tokens[b], tokens[a]\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "# p 확률로 단어를 삭제\n",
    "def RD(tokens, p):\n",
    "    # p 확률로 삭제할 단어 개수 계산\n",
    "    num_del = int(len(tokens) * p)\n",
    "    # num_del만큼 삭제할 단어의 인덱스 선택(pop하기 위해 정렬)\n",
    "    del_idx_list = list(range(0, len(tokens)))\n",
    "    random.shuffle(del_idx_list)\n",
    "    del_idx_list = sorted(del_idx_list[:num_del], reverse=True)\n",
    "    \n",
    "    for del_idx in del_idx_list:\n",
    "        tokens.pop(del_idx)\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# augmentation\n",
    "def augment_token(tokens, mode):\n",
    "    augment_token = []\n",
    "    if mode == 'SR':\n",
    "        augment_token = SR(tokens.copy(), n_a)\n",
    "    elif mode == 'RI':\n",
    "        augment_token = RI(tokens.copy(), n_a)\n",
    "    elif mode == 'RS':\n",
    "        augment_token = RS(tokens.copy(), n_a)\n",
    "    elif mode == 'RD':\n",
    "        augment_token = RD(tokens.copy(), del_p)\n",
    "    \n",
    "    return augment_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59532eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sess01_script01_User001F_001</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[아, 친구, 들, 도]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sess01_script01_User001F_002</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[는, 생일]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sess01_script01_User001F_003</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[생일날, 이, 면은, 가, 고기, 되게, 좋, 아, 하, 니까, 엄마, 도, 그걸...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sess01_script01_User001F_005</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[용돈, 으로, 주, 시, 고]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sess01_script01_User001F_006</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[옛날, 에, 는, 가, 원, 하, 는, 게, 뭔지, 일단, 물, 어, 보, 시, ...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sess01_script01_User001F_007</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[옷, 이, 라든가, 갖, 고, 싶, 은, 거, 있, 나라, 든가, 근데, 이제, ...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sess01_script01_User001F_008</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[응, 도, 되게, 여행, 가, 는, 걸, 좋, 아, 하, 긴, 하, 는데, 가족,...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sess01_script01_User001F_009</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[어, 단, 둘, 이]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sess01_script01_User001F_010</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[그, 되게, 아빠, 나, 오빠, 가, 시간, 이, 안, 나, 거나, 꼭, 약속, ...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sess01_script01_User001F_011</td>\n",
       "      <td>neutral</td>\n",
       "      <td>4</td>\n",
       "      <td>[여행, 여행]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      segment_id  emotion  emotion_id  \\\n",
       "4   Sess01_script01_User001F_001  neutral           4   \n",
       "12  Sess01_script01_User001F_002  neutral           4   \n",
       "13  Sess01_script01_User001F_003  neutral           4   \n",
       "17  Sess01_script01_User001F_005  neutral           4   \n",
       "18  Sess01_script01_User001F_006  neutral           4   \n",
       "19  Sess01_script01_User001F_007  neutral           4   \n",
       "31  Sess01_script01_User001F_008  neutral           4   \n",
       "33  Sess01_script01_User001F_009  neutral           4   \n",
       "35  Sess01_script01_User001F_010  neutral           4   \n",
       "36  Sess01_script01_User001F_011  neutral           4   \n",
       "\n",
       "                                                token  token_len  \n",
       "4                                       [아, 친구, 들, 도]          4  \n",
       "12                                            [는, 생일]          2  \n",
       "13  [생일날, 이, 면은, 가, 고기, 되게, 좋, 아, 하, 니까, 엄마, 도, 그걸...         48  \n",
       "17                                  [용돈, 으로, 주, 시, 고]          5  \n",
       "18  [옛날, 에, 는, 가, 원, 하, 는, 게, 뭔지, 일단, 물, 어, 보, 시, ...         20  \n",
       "19  [옷, 이, 라든가, 갖, 고, 싶, 은, 거, 있, 나라, 든가, 근데, 이제, ...         22  \n",
       "31  [응, 도, 되게, 여행, 가, 는, 걸, 좋, 아, 하, 긴, 하, 는데, 가족,...         33  \n",
       "33                                       [어, 단, 둘, 이]          4  \n",
       "35  [그, 되게, 아빠, 나, 오빠, 가, 시간, 이, 안, 나, 거나, 꼭, 약속, ...         31  \n",
       "36                                           [여행, 여행]          2  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['emotion_id']==4].sort_values('segment_id').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ddc34f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증강\n",
    "\n",
    "x = {0: 90, 1: 200, 2: 260, 3: 10, 4: 1, 5: 100, 6: 90}\n",
    "\n",
    "for i in [0,1,2,3,5,6]:\n",
    "    a = train[train['emotion_id']== i].sample(frac=x[i], replace = True)\n",
    "    if i < 1:\n",
    "        aug_df = a\n",
    "    else : aug_df = pd.concat([aug_df, a], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0559fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10140,\n",
       " 67900,\n",
       "                         segment_id emotion  emotion_id  \\\n",
       " 4432  Sess19_script06_User038F_015   angry           0   \n",
       " 1241  Sess08_script02_User016F_029   angry           0   \n",
       " 4750  Sess21_script02_User042F_018   angry           0   \n",
       " 1569  Sess09_script02_User018M_001   angry           0   \n",
       " 8672  Sess35_script04_User069F_023   angry           0   \n",
       " \n",
       "                                                   token  token_len  \n",
       " 4432                     [어, 랑, 친해져서, 그, 친구, 랑, 친해, 지려]          8  \n",
       " 1241  [아, 더, 어이없, 는, 거, 인사, 하, 면, 막상, 하, 면, 받, 아, 주,...         18  \n",
       " 4750  [근데, 는, 어쨌든, 그, 말, 듣, 고서, 간, 건데, 오히려, 안, 온, 애,...         48  \n",
       " 1569  [아, 근데, 너무, 좀, 화, 짜증, 나, 는, 게, 이게, 꼰대, 의, 기준, ...         23  \n",
       " 8672  [는, 이런, 쓰레기, 같, 은, 사람, 소개, 시켜, 주, 냐고, 도, 몰랐, 다...         35  )"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(aug_df), aug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e810fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>Sess19_script06_User038F_015</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[어, 랑, 친해져서, 그, 친구, 랑, 친해, 지려]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>Sess08_script02_User016F_029</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[아, 더, 어이없, 는, 거, 인사, 하, 면, 막상, 하, 면, 받, 아, 주,...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>Sess21_script02_User042F_018</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[근데, 는, 어쨌든, 그, 말, 듣, 고서, 간, 건데, 오히려, 안, 온, 애,...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>Sess09_script02_User018M_001</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[아, 근데, 너무, 좀, 화, 짜증, 나, 는, 게, 이게, 꼰대, 의, 기준, ...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>Sess35_script04_User069F_023</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[는, 이런, 쓰레기, 같, 은, 사람, 소개, 시켜, 주, 냐고, 도, 몰랐, 다...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        segment_id emotion  emotion_id  \\\n",
       "4432  Sess19_script06_User038F_015   angry           0   \n",
       "1241  Sess08_script02_User016F_029   angry           0   \n",
       "4750  Sess21_script02_User042F_018   angry           0   \n",
       "1569  Sess09_script02_User018M_001   angry           0   \n",
       "8672  Sess35_script04_User069F_023   angry           0   \n",
       "\n",
       "                                                  token  token_len  \n",
       "4432                     [어, 랑, 친해져서, 그, 친구, 랑, 친해, 지려]          8  \n",
       "1241  [아, 더, 어이없, 는, 거, 인사, 하, 면, 막상, 하, 면, 받, 아, 주,...         18  \n",
       "4750  [근데, 는, 어쨌든, 그, 말, 듣, 고서, 간, 건데, 오히려, 안, 온, 애,...         48  \n",
       "1569  [아, 근데, 너무, 좀, 화, 짜증, 나, 는, 게, 이게, 꼰대, 의, 기준, ...         23  \n",
       "8672  [는, 이런, 쓰레기, 같, 은, 사람, 소개, 시켜, 주, 냐고, 도, 몰랐, 다...         35  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8eb809b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67900/67900 [1:42:04<00:00, 11.09it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 3가지 데이터 증강 기법 랜덤 적용\n",
    "from tqdm import tqdm\n",
    "aug_result = []\n",
    "aug_func = ['SR', 'RI', 'RS']\n",
    "for tokens in tqdm(aug_df['token']):\n",
    "    func_idx = random.randrange(0,3) # 사용할 증강 \n",
    "    func_nm = aug_func[func_idx]\n",
    "    \n",
    "    augmented = augment_token(tokens, mode = func_nm)\n",
    "    aug_result.append(augmented)\n",
    "\n",
    "aug_df['augmented'] = aug_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0da49e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장\n",
    "import pickle\n",
    "\n",
    "aug_df.to_pickle(path+'augNonNP_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2d1549d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67900, 10140)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aug_df), len(train)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "16wU_p837SnXd72O6j_9wlL1l_BNlDpGR",
     "timestamp": 1680934778230
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
