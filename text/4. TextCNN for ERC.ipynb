{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "382b58c7",
   "metadata": {
    "id": "382b58c7"
   },
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4036144e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:42:32.841417Z",
     "start_time": "2023-04-19T06:41:36.704730Z"
    },
    "id": "4036144e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\erc_ETRI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "# from gensim.models import fasttext\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchmetrics import F1Score, ConfusionMatrix\n",
    "import time\n",
    "\n",
    "import gensim\n",
    "from gensim.models import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ft_path = '.' # fast text가 저장된 경로\n",
    "ft_model = gensim.models.fasttext.load_facebook_model( ft_path + '/wiki.ko.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4692ff5d",
   "metadata": {
    "id": "4692ff5d"
   },
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572bdf9",
   "metadata": {
    "id": "7572bdf9"
   },
   "source": [
    "## 필요한 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "035734ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:42.944246Z",
     "start_time": "2023-04-19T06:27:42.634390Z"
    },
    "id": "035734ab",
    "outputId": "32c4ba9d-ea98-4ff6-fe07-430d34b2356d",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>token</th>\n",
       "      <th>token_len</th>\n",
       "      <th>augmented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4432</th>\n",
       "      <td>Sess19_script06_User038F_015</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[어, 랑, 친해져서, 그, 친구, 랑, 친해, 지려]</td>\n",
       "      <td>8</td>\n",
       "      <td>[랑, 어, 친해져서, 그, 친구, 친해, 랑, 지려]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4528</th>\n",
       "      <td>Sess20_script02_User039M_039</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[또, 계산, 안, 해, 가지, 고]</td>\n",
       "      <td>6</td>\n",
       "      <td>[또, 계산, 안, 고, 가지, 해]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5640</th>\n",
       "      <td>Sess25_script02_User050F_024</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[친구, 도, 아니, 다]</td>\n",
       "      <td>4</td>\n",
       "      <td>[친구, 도, 아니, 둘]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>Sess16_script06_User031M_020</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[아, 욕, 나와, 욕, 나올, 거, 같, 은데, 욕, 나올, 거, 같, 은데, 암...</td>\n",
       "      <td>17</td>\n",
       "      <td>[거, 아, 나와, 어, 나올, 욕, 나올, 은데, 욕, 같, 거, 같, 욕, 암튼...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>Sess09_script02_User018M_008</td>\n",
       "      <td>angry</td>\n",
       "      <td>0</td>\n",
       "      <td>[는, 좀, 되게, 화, 가]</td>\n",
       "      <td>5</td>\n",
       "      <td>[는, 좀, 되게, 화, 와]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        segment_id emotion  emotion_id  \\\n",
       "4432  Sess19_script06_User038F_015   angry           0   \n",
       "4528  Sess20_script02_User039M_039   angry           0   \n",
       "5640  Sess25_script02_User050F_024   angry           0   \n",
       "3593  Sess16_script06_User031M_020   angry           0   \n",
       "1578  Sess09_script02_User018M_008   angry           0   \n",
       "\n",
       "                                                  token  token_len  \\\n",
       "4432                     [어, 랑, 친해져서, 그, 친구, 랑, 친해, 지려]          8   \n",
       "4528                               [또, 계산, 안, 해, 가지, 고]          6   \n",
       "5640                                     [친구, 도, 아니, 다]          4   \n",
       "3593  [아, 욕, 나와, 욕, 나올, 거, 같, 은데, 욕, 나올, 거, 같, 은데, 암...         17   \n",
       "1578                                   [는, 좀, 되게, 화, 가]          5   \n",
       "\n",
       "                                              augmented  \n",
       "4432                     [랑, 어, 친해져서, 그, 친구, 친해, 랑, 지려]  \n",
       "4528                               [또, 계산, 안, 고, 가지, 해]  \n",
       "5640                                     [친구, 도, 아니, 둘]  \n",
       "3593  [거, 아, 나와, 어, 나올, 욕, 나올, 은데, 욕, 같, 거, 같, 욕, 암튼...  \n",
       "1578                                   [는, 좀, 되게, 화, 와]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './dataset/KEMDy20_v1_1/new/text'\n",
    "ann_path = './dataset/KEMDy20_v1_1/annotation'\n",
    "\n",
    "# 저장한 데이터 토큰 피클 파일 불러오기\n",
    "with open(path + '/token_NonNP.pkl', 'rb') as f:\n",
    "    text_data = pickle.load(f)\n",
    "\n",
    "text_data['token_len'] = [len(x) for x in text_data['token']]\n",
    "\n",
    "# train용 aug token data\n",
    "with open(path + '/augNonNP_df.pkl', 'rb') as f:\n",
    "    text_data2 = pickle.load(f)\n",
    "\n",
    "# 다중 레이블 처리한 훈련 데이터셋 가져오기\n",
    "with open(ann_path + '/train_origin.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "\n",
    "# 다중 레이블 처리한 테스트 데이터셋 가져오기\n",
    "with open(ann_path + '/test_origin.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "\n",
    "text_data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f4a005b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:46.818291Z",
     "start_time": "2023-04-19T06:27:46.803265Z"
    },
    "id": "9f4a005b"
   },
   "outputs": [],
   "source": [
    "# 필요한 컬럼만 남겨두기\n",
    "#train_data = train_data.drop(['seconds', 'sess', 'script'], axis=1)\n",
    "test_data = test_data.drop(['seconds', 'sess', 'script'], axis=1)\n",
    "\n",
    "# 텍스트에서 필요한 컬럼만 남겨두기 및 컬럼 이름 맞추기\n",
    "text_data = text_data[['segment_id', 'token','token_len']]\n",
    "text_data2 = text_data2[['segment_id','emotion','emotion_id','augmented','token_len']]\n",
    "text_data2 = text_data2.rename(columns={'augmented':'token'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208a2a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:48.893942Z",
     "start_time": "2023-04-19T06:27:48.874474Z"
    },
    "id": "208a2a54"
   },
   "outputs": [],
   "source": [
    "# 훈련 및 테스트 데이터에 텍스트 데이터 붙이기\n",
    "train = text_data2\n",
    "test = pd.merge(test_data, text_data, how='left', on=['segment_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e01c8928",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:50.440732Z",
     "start_time": "2023-04-19T06:27:50.426257Z"
    },
    "id": "e01c8928",
    "outputId": "c553746e-63e2-43f1-f785-e706921c6011"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67900, 8750)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(train[train['emotion_id']==4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e5fe494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:52.189305Z",
     "start_time": "2023-04-19T06:27:52.137088Z"
    },
    "id": "1e5fe494",
    "outputId": "537ce0c9-cb50-4278-daca-0fcfca44576a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10140"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "len(np.unique(train['segment_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7e9f09c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:53.803427Z",
     "start_time": "2023-04-19T06:27:53.786472Z"
    },
    "id": "f7e9f09c",
    "outputId": "e0207688-63d4-4672-d102-4f0f68d2261c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "977"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_class = len(train_data[train_data['emotion_id']==3])\n",
    "max_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15eb2d2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:55.294186Z",
     "start_time": "2023-04-19T06:27:55.259306Z"
    },
    "id": "15eb2d2b",
    "outputId": "444c1b71-5198-4dd1-b37b-fc4fef84526a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 class :  977\n",
      "1 class :  977\n",
      "2 class :  977\n",
      "5 class :  977\n",
      "6 class :  977\n",
      "3 class :  977\n",
      "4 class :  8750\n"
     ]
    }
   ],
   "source": [
    "# 원래 happy 데이터\n",
    "happy_origin = pd.merge(train_data[train_data['emotion']=='happy'], text_data, how='left', on='segment_id')[['segment_id','emotion','emotion_id', 'token', 'token_len']]\n",
    "\n",
    "for i in [0,1,2,5,6]:\n",
    "    a = train[train['emotion_id']==i].sample(n=max_class,replace=F, random_state=42)\n",
    "    if i < 1:\n",
    "        data = a\n",
    "    else:\n",
    "        data = pd.concat([data, a], axis=0)\n",
    "    print(i,\"class : \",len(data[data['emotion_id']==i]))\n",
    "data = pd.concat([data, happy_origin])\n",
    "data = pd.concat([data, train[train['emotion_id']==4]], axis=0)\n",
    "len(data)\n",
    "print(\"3 class : \",len(data[data['emotion_id']==3]))\n",
    "print(\"4 class : \",len(data[data['emotion_id']==4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "176c1746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:57.399407Z",
     "start_time": "2023-04-19T06:27:57.395418Z"
    },
    "id": "176c1746"
   },
   "outputs": [],
   "source": [
    "train = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67be76b",
   "metadata": {
    "id": "b67be76b"
   },
   "source": [
    "## 텍스트 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a120eca7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:27:59.263611Z",
     "start_time": "2023-04-19T06:27:59.250676Z"
    },
    "id": "a120eca7",
    "outputId": "6e2d50f2-4880-4938-8650-19fd0127c0be",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최대 토큰 개수 구하기\n",
    "max_token = train['token_len'].max()\n",
    "max_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05e03c40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:01.317512Z",
     "start_time": "2023-04-19T06:28:01.297594Z"
    },
    "id": "05e03c40",
    "outputId": "e73a3596-2bdf-4ff9-a1e8-c3c6fb0adf64",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_id</th>\n",
       "      <th>token_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14612.000000</td>\n",
       "      <td>14612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.531960</td>\n",
       "      <td>16.038530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.456463</td>\n",
       "      <td>14.072077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         emotion_id     token_len\n",
       "count  14612.000000  14612.000000\n",
       "mean       3.531960     16.038530\n",
       "std        1.456463     14.072077\n",
       "min        0.000000      1.000000\n",
       "25%        3.000000      6.000000\n",
       "50%        4.000000     11.000000\n",
       "75%        4.000000     21.000000\n",
       "max        6.000000    150.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50a1d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:02.679986Z",
     "start_time": "2023-04-19T06:28:02.674032Z"
    },
    "id": "c50a1d25"
   },
   "outputs": [],
   "source": [
    "max_token = int(train.describe()['token_len'].loc['75%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e96e6a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:05.045704Z",
     "start_time": "2023-04-19T06:28:05.027215Z"
    },
    "id": "8e96e6a8"
   },
   "outputs": [],
   "source": [
    "def get_embedding(data):\n",
    "    # 텍스트 임베딩\n",
    "    text_emb = []\n",
    "    for tokens in tqdm(data['token']):\n",
    "        sent_emb = []\n",
    "        for i in range(max_token):\n",
    "            # 워드 임베딩 초기화\n",
    "            word_emb = []\n",
    "\n",
    "            # 최대 단어 길이(156) 이하면 패딩\n",
    "            if i >= len(tokens):\n",
    "                word_emb = [np.array([0.]*300, dtype='float32')]*(max_token-i)\n",
    "                sent_emb.extend(word_emb)\n",
    "                break;\n",
    "\n",
    "            # fasttext 워드 임베딩 가져옴\n",
    "            word_emb = ft_model.wv[tokens[i]]\n",
    "            sent_emb.append(word_emb)\n",
    "\n",
    "        text_emb.append(sent_emb)\n",
    "\n",
    "    data['text_emb'] = text_emb\n",
    "    return data['text_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1d5318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:07.577162Z",
     "start_time": "2023-04-19T06:28:06.857704Z"
    },
    "id": "9f1d5318",
    "outputId": "a0be529d-bb40-4e5e-9ef1-fdca305e1990",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14612/14612 [00:00<00:00, 32856.05it/s]\n",
      "100%|██████████| 2614/2614 [00:00<00:00, 36961.45it/s]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋에 텍스트 임베딩 추가하기\n",
    "train['text_emb'] = get_embedding(train)\n",
    "test['text_emb'] = get_embedding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1580e93f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:08.582654Z",
     "start_time": "2023-04-19T06:28:08.530255Z"
    },
    "id": "1580e93f",
    "outputId": "4a571833-43fc-4ea8-c653-b9d26df9d259",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6146    [[0.18122339, 0.20740172, -0.12993784, 0.01915...\n",
       "618     [[-0.2459137, 0.14915791, -0.8468651, 0.109163...\n",
       "6929    [[-0.9367216, 0.85393, -1.3444862, -0.25269663...\n",
       "3332    [[-0.24933465, 0.42417058, -0.72755027, -0.392...\n",
       "4528    [[-0.16821234, 0.26754832, -0.41189933, 0.0361...\n",
       "Name: text_emb, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 임베딩 결과 확인\n",
    "train['text_emb'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d2c7e9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:09.895571Z",
     "start_time": "2023-04-19T06:28:09.842297Z"
    },
    "id": "6d2c7e9f",
    "outputId": "0da7b4e5-d6d4-46e6-fa74-8df5020bfe32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[-0.9367216, 0.85393, -1.3444862, -0.25269663...\n",
       "1    [[-0.19490944, -0.06741688, -0.23153214, 0.168...\n",
       "2    [[-1.0400262, 0.25054872, -1.7955443, -0.41869...\n",
       "3    [[-0.004059928, 0.08098799, -0.5521582, 0.2013...\n",
       "4    [[-0.40613854, 0.21009226, -0.21392642, 0.1807...\n",
       "Name: text_emb, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text_emb'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c2de5",
   "metadata": {
    "id": "166c2de5"
   },
   "source": [
    "# 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e434a56a",
   "metadata": {
    "id": "e434a56a"
   },
   "source": [
    "## 데이터셋 및 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4f4f784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:13.088602Z",
     "start_time": "2023-04-19T06:28:13.082619Z"
    },
    "id": "c4f4f784"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e2f442c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:14.410292Z",
     "start_time": "2023-04-19T06:28:14.395361Z"
    },
    "id": "5e2f442c"
   },
   "outputs": [],
   "source": [
    "# 레이블에 대해 정수 인코딩\n",
    "encoder = LabelEncoder()\n",
    "train_label = encoder.fit_transform(train[['emotion']].to_numpy().reshape(-1))\n",
    "test_label = encoder.transform(test[['emotion']].to_numpy().reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7bf1eca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:15.919305Z",
     "start_time": "2023-04-19T06:28:15.905343Z"
    },
    "id": "d7bf1eca"
   },
   "outputs": [],
   "source": [
    "# 텍스트 데이터셋 만들기\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, mode):\n",
    "        self.mode = mode\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(train['text_emb'], train_label, test_size=0.1, random_state=42)\n",
    "        if self.mode == 'train':\n",
    "            self.x_data = torch.FloatTensor(X_train.array)\n",
    "            self.y_data = torch.LongTensor(y_train)\n",
    "        elif self.mode == 'valid':\n",
    "            self.x_data = torch.FloatTensor(X_valid.array)\n",
    "            self.y_data = torch.LongTensor(y_valid)\n",
    "        else:\n",
    "            self.x_data = torch.FloatTensor(test['text_emb'].array)\n",
    "            self.y_data = torch.LongTensor(test_label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x_data[idx]\n",
    "        y = self.y_data[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7cf8674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:17.494332Z",
     "start_time": "2023-04-19T06:28:17.473358Z"
    },
    "id": "a7cf8674"
   },
   "outputs": [],
   "source": [
    "# textCNN 모델 구성\n",
    "class textCNN(nn.Module):\n",
    "    def __init__(self, dim_channel, kernel_wins, dropout_rate, num_class):\n",
    "        super(textCNN, self).__init__()\n",
    "        self.emb_dim = 300\n",
    "        # 커널 사이즈에 따라 CNN 설정(kernel_wins)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, dim_channel, (w, self.emb_dim)) for w in kernel_wins])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        # CNN에서 나온 값 합치기\n",
    "        self.ft_fc = nn.Linear(len(kernel_wins)*dim_channel, 128)\n",
    "        self.fc = nn.Linear(128, num_class)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        emb_x = x.unsqueeze(1)\n",
    "        \n",
    "        conv_x = [conv(emb_x) for conv in self.convs]\n",
    "        \n",
    "        pool_x = [F.max_pool1d(x.squeeze(-1), x.size()[2]) for x in conv_x]\n",
    "        \n",
    "        fc_x = torch.cat(pool_x, dim=1)\n",
    "        fc_x = fc_x.squeeze(-1)\n",
    "        fc_x = F.relu(fc_x)\n",
    "        fc_x = self.dropout(fc_x)\n",
    "        ft_fc = self.ft_fc(fc_x)\n",
    "        fc_x = self.fc(ft_fc)\n",
    "#         logit = self.softmax(fc_x)\n",
    "        logit = fc_x\n",
    "        return logit, ft_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2b16c6be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:24.001913Z",
     "start_time": "2023-04-19T06:28:23.978973Z"
    },
    "id": "2b16c6be",
    "outputId": "a258b30d-c7e8-458c-e928-2cd03d25f5d2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textCNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(4, 300), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(5, 300), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      "  (ft_fc): Linear(in_features=200, out_features=128, bias=True)\n",
      "  (fc): Linear(in_features=128, out_features=7, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정 및 모델 생성\n",
    "learning_rate = 0.0005\n",
    "dim_channel = 100\n",
    "kernel_wins = [4,5] ## 논문대로 설정\n",
    "dropout_rate = 0.4\n",
    "num_class = len(encoder.classes_)\n",
    "\n",
    "model = textCNN(dim_channel=dim_channel, kernel_wins=kernel_wins, dropout_rate=dropout_rate, num_class=num_class);\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss();\n",
    "# criterion = FocalLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "60678977",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:32.826140Z",
     "start_time": "2023-04-19T06:28:26.051289Z"
    },
    "id": "60678977"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 생성(40초 가량 소요)\n",
    "train_dataset = TextDataset(mode='train')\n",
    "valid_dataset = TextDataset(mode='valid')\n",
    "test_dataset = TextDataset(mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23cde63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:28:32.841399Z",
     "start_time": "2023-04-19T06:28:32.828105Z"
    },
    "id": "23cde63c"
   },
   "outputs": [],
   "source": [
    "# 데이터로더 생성\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab42db1b",
   "metadata": {
    "id": "ab42db1b"
   },
   "source": [
    "## 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "df141160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:46:17.269054Z",
     "start_time": "2023-04-19T06:45:46.162100Z"
    },
    "id": "df141160",
    "outputId": "ffcca414-2748-4f87-8739-b5b5129714e3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.002885283902287483\n",
      "Epoch: 20, Loss: 0.000601716514211148\n",
      "Epoch: 30, Loss: 0.04175012186169624\n",
      "Epoch: 40, Loss: 0.0004919555503875017\n",
      "Epoch: 50, Loss: 0.0015360425459221005\n",
      "Epoch: 60, Loss: 0.0010186773724853992\n",
      "Epoch: 70, Loss: 0.01396716758608818\n",
      "Time: 137.69167304039001\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "# 모델 학습\n",
    "num_epochs = 70\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    for x_data, y_data in train_loader:\n",
    "        x_data, y_data = x_data.to(device), y_data.to(device)\n",
    "        \n",
    "        train_x = Variable(x_data.view(x_data.shape[0], max_token, 300))\n",
    "        labels = Variable(y_data)\n",
    "        \n",
    "        outputs, _ = model(train_x)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if not (epoch % 10):\n",
    "        label_list = []\n",
    "        predict_list = []\n",
    "        for x_data, y_data in valid_loader:\n",
    "            x_data, y_data = x_data.to(device), y_data.to(device)\n",
    "            \n",
    "            test_x = Variable(x_data.view(x_data.shape[0], max_token, 300))\n",
    "            outputs, _ = model(test_x)\n",
    "            predictions = torch.max(outputs,1)[1].to(device)\n",
    "\n",
    "            label_list.extend(y_data)\n",
    "            predict_list.extend(predictions)\n",
    "\n",
    "#         predict_list = torch.tensor(predict_list)\n",
    "#         label_list = torch.tensor(label_list)\n",
    "        \n",
    "#         f1 = F1Score(task='multiclass', num_classes=7)\n",
    "#         f1_score = f1(predict_list, label_list)\n",
    "        \n",
    "        print('Epoch: {}, Loss: {}'.format(epoch, loss.data))\n",
    "end_time = time.time()\n",
    "print('Time:', end_time-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75573663",
   "metadata": {
    "id": "75573663"
   },
   "source": [
    "# 성능 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d2bb7",
   "metadata": {
    "id": "ec8d2bb7"
   },
   "source": [
    "## 테스트셋 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d36f58da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:46:28.384800Z",
     "start_time": "2023-04-19T06:46:28.113007Z"
    },
    "id": "d36f58da",
    "outputId": "6b90c41e-3ed4-404c-aaab-f80d015b6002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8485)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "# 테스트셋에서의 f1스코어\n",
    "predictions_list4 = []\n",
    "labels_list4 = []\n",
    "for x_data, y_data in test_loader:\n",
    "    x_data, y_data = x_data.to(device), y_data.to(device)\n",
    "    labels_list4.extend(y_data)\n",
    "    test_x = Variable(x_data.view(x_data.shape[0], max_token, 300))\n",
    "    outputs, feature = model(test_x)\n",
    "    \n",
    "    predictions4 = torch.max(outputs,1)[1].cpu()\n",
    "    predictions_list4.extend(predictions4)\n",
    "    \n",
    "predictions_list4 = torch.tensor(predictions_list4)\n",
    "labels_list4 = torch.tensor(labels_list4)\n",
    "\n",
    "f1 = F1Score(task='multiclass', num_classes=7)\n",
    "f1_score = f1(predictions_list4, labels_list4)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5701182",
   "metadata": {
    "id": "f5701182"
   },
   "source": [
    "## 훈련셋 성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca4f7bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:46:31.241252Z",
     "start_time": "2023-04-19T06:46:30.073207Z"
    },
    "id": "ca4f7bd5",
    "outputId": "6abb3bec-bf84-40c9-f227-25e4506a54d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9996)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋에서의 f1스코어\n",
    "predictions_list3 = []\n",
    "labels_list3 = []\n",
    "for x_data, y_data in train_loader:\n",
    "    x_data, y_data = x_data.to(device), y_data.to(device)\n",
    "    labels_list3.extend(y_data)\n",
    "    test_x = Variable(x_data.view(x_data.shape[0], max_token, 300))\n",
    "    outputs, feature = model(test_x)\n",
    "    \n",
    "    predictions3 = torch.max(outputs,1)[1].to(device)\n",
    "    #print(predictions3)\n",
    "    predictions_list3.extend(predictions3)\n",
    "    \n",
    "predictions_list3 = torch.tensor(predictions_list3)\n",
    "labels_list3 = torch.tensor(labels_list3)\n",
    "\n",
    "f1 = F1Score(task='multiclass', num_classes=7)\n",
    "f1_score = f1(predictions_list3, labels_list3)\n",
    "f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9731a5",
   "metadata": {
    "id": "cc9731a5"
   },
   "source": [
    "## 클래스별 예측 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2a895c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:33:27.666013Z",
     "start_time": "2023-04-19T06:33:27.650056Z"
    },
    "id": "2a895c6d",
    "outputId": "3ef2242c-9681-4e9f-8072-2673e2beb6dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train)Origin Label:\n",
      " [('neutral', 7846), ('surprise', 890), ('disgust', 886), ('happy', 885), ('angry', 883), ('sad', 881), ('fear', 879)]\n",
      "(train)Pred:\n",
      " [('neutral', 7851), ('surprise', 890), ('disgust', 886), ('angry', 883), ('sad', 881), ('happy', 880), ('fear', 879)]\n",
      "\n",
      "\n",
      "(test)Origin Label:\n",
      " [('neutral', 2310), ('happy', 194), ('angry', 38), ('surprise', 27), ('sad', 24), ('disgust', 15), ('fear', 6)]\n",
      "(test)Pred:\n",
      " [('neutral', 2419), ('happy', 130), ('angry', 26), ('sad', 13), ('fear', 11), ('surprise', 9), ('disgust', 6)]\n",
      "\n",
      "\n",
      "(train)accuracy: 0.8996030659731727\n",
      "(train)F1-score: tensor(0.9996)\n",
      "\n",
      "(test)accuracy: 0.8485080336648814\n",
      "(train)F1-score: tensor(0.8485)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 클래스 별로 예측 값 개수 확인\n",
    "label_origin3 = encoder.inverse_transform(labels_list3)\n",
    "pred_origin3 = encoder.inverse_transform(predictions_list3)\n",
    "\n",
    "label_origin4 = encoder.inverse_transform(labels_list4)\n",
    "pred_origin4 = encoder.inverse_transform(predictions_list4)\n",
    "\n",
    "label_counter3 = Counter(label_origin3)\n",
    "pred_counter3 = Counter(pred_origin3)\n",
    "\n",
    "label_counter4 = Counter(label_origin4)\n",
    "pred_counter4 = Counter(pred_origin4)\n",
    "\n",
    "print(\"(train)Origin Label:\\n\", label_counter3.most_common(), end='\\n')\n",
    "print(\"(train)Pred:\\n\", pred_counter3.most_common(), end='\\n\\n\\n')\n",
    "\n",
    "print(\"(test)Origin Label:\\n\", label_counter4.most_common(), end='\\n')\n",
    "print(\"(test)Pred:\\n\", pred_counter4.most_common(), end='\\n\\n\\n')\n",
    "\n",
    "corrects3 = [x for x, y in zip(label_origin3, pred_origin3) if x==y]\n",
    "corrects4 = [x for x, y in zip(label_origin4, pred_origin4) if x==y]\n",
    "correct_counter3 = Counter(corrects3)\n",
    "correct_counter4 = Counter(corrects4)\n",
    "\n",
    "print(\"(train)accuracy:\",len(corrects3)/len(train), end='\\n')\n",
    "print(\"(train)F1-score:\",f1(predictions_list3, labels_list3), end='\\n\\n')\n",
    "print(\"(test)accuracy:\",len(corrects4)/len(test), end='\\n')\n",
    "print(\"(train)F1-score:\",f1(predictions_list4, labels_list4), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1dc0213a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:33:29.747919Z",
     "start_time": "2023-04-19T06:33:29.729411Z"
    },
    "id": "1dc0213a",
    "outputId": "006e31d2-52ec-4801-aa90-3cf0b11ccd6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
      "tensor([[ 883,    0,    0,    0,    0,    0,    0],\n",
      "        [   0,  886,    0,    0,    0,    0,    0],\n",
      "        [   0,    0,  879,    0,    0,    0,    0],\n",
      "        [   0,    0,    0,  881,    4,    0,    0],\n",
      "        [   0,    0,    0,    3, 7843,    0,    0],\n",
      "        [   0,    0,    0,    0,    0,  881,    0],\n",
      "        [   0,    0,    0,    0,    1,    0,  889]])\n",
      "(train)accuracy: 0.8993977552696414\n",
      "(train)F1-score: tensor(0.9994)\n"
     ]
    }
   ],
   "source": [
    "# train 성능\n",
    "print(encoder.classes_)\n",
    "confmat = ConfusionMatrix(task='multiclass',num_classes = 7)\n",
    "print(confmat(predictions_list3, labels_list3))\n",
    "f1_score = f1(predictions_list3, labels_list3)\n",
    "print(\"(train)accuracy:\",len(corrects3)/len(train), end='\\n')\n",
    "print(\"(train)F1-score:\",f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "39c8aadc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:33:31.274011Z",
     "start_time": "2023-04-19T06:33:31.258054Z"
    },
    "id": "39c8aadc",
    "outputId": "ec1d9992-95c7-40cc-e72a-2ae7d50b7339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n",
      "tensor([[   3,    0,    0,    1,   33,    0,    1],\n",
      "        [   1,    3,    1,    0,   10,    0,    0],\n",
      "        [   0,    0,    4,    0,    2,    0,    0],\n",
      "        [   3,    0,    0,   29,  161,    1,    0],\n",
      "        [  18,    3,    6,   98, 2173,    8,    4],\n",
      "        [   0,    0,    0,    1,   21,    2,    0],\n",
      "        [   1,    0,    0,    1,   19,    2,    4]])\n",
      "(test)accuracy: 0.8485080336648814\n",
      "(test)F1-score: tensor(0.8485)\n"
     ]
    }
   ],
   "source": [
    "#test 성능\n",
    "\n",
    "print(encoder.classes_)\n",
    "print(confmat(predictions_list4, labels_list4))\n",
    "f1_score4 = f1(predictions_list4, labels_list4)\n",
    "print(\"(test)accuracy:\",len(corrects4)/len(test), end='\\n')\n",
    "print(\"(test)F1-score:\",f1_score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f55688e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:33:32.759007Z",
     "start_time": "2023-04-19T06:33:32.746042Z"
    },
    "id": "f55688e6",
    "outputId": "ae1672e9-25c1-4eb2-9d30-199a6fb3cc00",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('neutral', 2173), ('happy', 29), ('surprise', 4), ('fear', 4), ('disgust', 3), ('angry', 3), ('sad', 2)]\n"
     ]
    }
   ],
   "source": [
    "corrects = [x for x, y in zip(label_origin4, pred_origin4) if x==y]\n",
    "\n",
    "correct_counter = Counter(corrects)\n",
    "print(correct_counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a76c0ab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T06:33:34.349784Z",
     "start_time": "2023-04-19T06:33:34.338839Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.12      0.09        26\n",
      "           1       0.20      0.50      0.29         6\n",
      "           2       0.67      0.36      0.47        11\n",
      "           3       0.15      0.22      0.18       130\n",
      "           4       0.94      0.90      0.92      2419\n",
      "           5       0.08      0.15      0.11        13\n",
      "           6       0.15      0.44      0.22         9\n",
      "\n",
      "    accuracy                           0.85      2614\n",
      "   macro avg       0.32      0.39      0.33      2614\n",
      "weighted avg       0.88      0.85      0.86      2614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn  import metrics\n",
    "print(metrics.classification_report(predictions_list4, labels_list4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54868193",
   "metadata": {},
   "source": [
    "# 앙상블을 위한 모델 결과 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6ff5039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame()\n",
    "session = []\n",
    "prediction = []\n",
    "for idx, (x_data, y_data) in enumerate(test_loader):\n",
    "    x_data, y_data = x_data.to(device), y_data.to(device)\n",
    "    test_x = Variable(x_data.view(x_data.shape[0], max_token, 300))\n",
    "    outputs, _ = model(test_x)\n",
    "    session.extend(test['segment_id'][idx*100:(idx+1)*100])\n",
    "    prediction.extend(outputs.tolist())\n",
    "#     predictions = torch.max(outputs,1)[1].to(device)\n",
    "#     predictions_list.extend(predictions)\n",
    "\n",
    "prediction = nn.Softmax(dim=1)(torch.Tensor(prediction)).cpu().detach().numpy()\n",
    "\n",
    "prediction_df['segment_id'] = session\n",
    "for idx, emotion in enumerate(encoder.classes_):\n",
    "    prediction_df[emotion] = prediction[:,idx]\n",
    "    \n",
    "prediction_df.to_csv(path + '/text_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174.162px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
