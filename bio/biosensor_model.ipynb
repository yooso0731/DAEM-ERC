{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#필요한 패키지 다운"
      ],
      "metadata": {
        "id": "T6JIjGj1CTga"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxvlQKGrCIho"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install imbalanced-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "TZeOo8DVCZ9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as  np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "train = pd.read_pickle('./dataset/KEMDy20_v1_1/sensor/bio_train/train_origin.pkl')\n",
        "test = pd.read_pickle('./dataset/KEMDy20_v1_1/sensor/bio_train/test_origin.pkl')\n",
        "\n",
        "# padding 및 SMOTE 진행한 데이터 불러오기\n",
        "temp_x = np.load('./dataset/KEMDy20_v1_1/sensor/bio_train/temp_x.npy')\n",
        "eda_x = np.load('./dataset/KEMDy20_v1_1/sensor/bio_train/eda_x.npy')\n",
        "t_y = np.load('./dataset/KEMDy20_v1_1/sensor/bio_train/t_y.npy')"
      ],
      "metadata": {
        "id": "Kkh5Q0AiCQlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "증강한 train 데이터 로더에 필요한 모듈 정의"
      ],
      "metadata": {
        "id": "b-ul6dOLEU4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class SmoteCustomDataset(Dataset):\n",
        "    def __init__(self, temp , eda, y):\n",
        "\n",
        "        self.temp_ten = torch.Tensor(temp)\n",
        "        self.eda_ten = torch.Tensor(eda)\n",
        "        \n",
        "        self.length = len(y)\n",
        "        self.t_y = torch.LongTensor(y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        t = self.temp_ten[index]\n",
        "        e = self.eda_ten[index]\n",
        "        y = self.t_y[index]\n",
        "        return t,e,y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "metadata": {
        "id": "-ai_1n8TCQpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BIO Sensor Data 모델 선언"
      ],
      "metadata": {
        "id": "wpCgBIwzEpoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 모델 선언\n",
        "\n",
        "import torch\n",
        "import torch.nn.init\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class bio_CNN(torch.nn.Module): \n",
        "  def __init__(self): \n",
        "    super(bio_CNN, self).__init__() \n",
        "\n",
        "    self.conv1 = torch.nn.Sequential(\n",
        "        torch.nn.Conv1d(in_channels=1, out_channels=4, kernel_size=3, stride=1), \n",
        "        torch.nn.BatchNorm1d(4),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.conv2 = torch.nn.Sequential(\n",
        "        torch.nn.Conv1d(in_channels=4, out_channels=8, kernel_size=3, stride=1),\n",
        "        torch.nn.BatchNorm1d(8),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.conv3 = torch.nn.Sequential(\n",
        "        torch.nn.Conv1d(in_channels=8, out_channels=12, kernel_size=3, stride=1),\n",
        "        torch.nn.BatchNorm1d(12),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.conv4 = torch.nn.Sequential(\n",
        "        torch.nn.Conv1d(in_channels=12, out_channels=16, kernel_size=3, stride=1),\n",
        "        torch.nn.BatchNorm1d(16),\n",
        "        torch.nn.ReLU(),\n",
        "    )\n",
        "\n",
        "\n",
        "    self.fc1 = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_features=133*32, out_features=1000, bias=True),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(in_features=1000, out_features=500, bias=True),\n",
        "        torch.nn.ReLU(),\n",
        "        torch.nn.Linear(in_features=500, out_features=128, bias=True),\n",
        "    )\n",
        "\n",
        "    self.fc2 = torch.nn.Sequential(\n",
        "        torch.nn.Linear(in_features=128, out_features=7, bias=True),\n",
        "    )\n",
        "\n",
        "    self.relu = torch.nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, t, e):\n",
        "    temp, eda = t, e\n",
        "    temp = torch.reshape(temp,(-1,1,141))\n",
        "    eda = torch.reshape(eda,(-1,1,141))\n",
        "\n",
        "    out_t = self.conv1(temp)\n",
        "    out_t = self.conv2(out_t)\n",
        "    out_t = self.conv3(out_t)\n",
        "    out_t = self.conv4(out_t)\n",
        "\n",
        "    out_e = self.conv1(eda)  \n",
        "    out_e = self.conv2(out_e)\n",
        "    out_e = self.conv3(out_e)\n",
        "    out_e = self.conv4(out_e)\n",
        "\n",
        "    out = torch.cat([out_t,out_e], dim=1)\n",
        "    out = torch.flatten(out,1)\n",
        "\n",
        "    out = self.fc1(out)\n",
        "    result = self.fc2(self.relu(out))\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "N5h4euLEEqCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 선언 및 최적화 함수 설정"
      ],
      "metadata": {
        "id": "wDS-go20Hui8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = bio_CNN().to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss().to(device) \n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001, weight_decay=2e-4)"
      ],
      "metadata": {
        "id": "gINNJcDAHoiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SmoteCustomDataset(temp_x, eda_x ,t_y)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=False)"
      ],
      "metadata": {
        "id": "lgc5u1SiHsW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델학습"
      ],
      "metadata": {
        "id": "tlvWva4FH12A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import F1Score, Accuracy\n",
        "\n",
        "model.train()\n",
        "\n",
        "for epoch in range(100):\n",
        "    cost = 0.0\n",
        "    labels_list = []\n",
        "    predictions_list = []\n",
        "\n",
        "    for t, e, y in train_dataloader:\n",
        "        t = t.to(device)\n",
        "        e = e.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        output = model(t, e)\n",
        "        loss = loss_fn(output, y)\n",
        "        labels_list.extend(y)\n",
        "        predictions = torch.max(output,1)[1].to(device)\n",
        "        predictions_list.extend(predictions)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cost += loss\n",
        "    cost = cost / len(train_dataloader)\n",
        "    predictions_list = torch.tensor(predictions_list)\n",
        "    labels_list = torch.tensor(labels_list)\n",
        "\n",
        "    f1 = F1Score(task='multiclass', num_classes=7)\n",
        "    f1_score = f1(predictions_list, labels_list)\n",
        "    auc = Accuracy(task='multiclass', num_classes=7)\n",
        "    auc_score = auc(predictions_list, labels_list)\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch : {epoch+1:4d}, Cost : {cost:.3f}, F1 : {f1_score:.3f}, Auc: {auc_score:.3f}\")"
      ],
      "metadata": {
        "id": "VNTL7-IRHmbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 F1 socre 및 Accuracy 확인"
      ],
      "metadata": {
        "id": "I9bmUwvIIJnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import F1Score, Accuracy\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "labels_list = []\n",
        "predictions_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for t, e, y in tqdm(train_dataloader):\n",
        "      t = t.to(device)\n",
        "      e = e.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      output = model(t,e)\n",
        "\n",
        "      labels_list.extend(y)\n",
        "      predictions = torch.max(output,1)[1].to(device)\n",
        "      predictions_list.extend(predictions)\n",
        "\n",
        "  predictions_list = torch.tensor(predictions_list)\n",
        "  labels_list = torch.tensor(labels_list)\n",
        "\n",
        "  f1 = F1Score(task='multiclass', num_classes=7)\n",
        "  f1_score = f1(predictions_list, labels_list)\n",
        "  auc = Accuracy(task='multiclass', num_classes=7)\n",
        "  auc_score = auc(predictions_list, labels_list)\n",
        "\n",
        "  print('f1:',f1_score, 'auc:',auc_score)"
      ],
      "metadata": {
        "id": "hsw0xZQBIEok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class별 예측 값 개수 확인"
      ],
      "metadata": {
        "id": "Mk7K483hIVm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dic = {0:'angry', 1:'disqust',2:'fear', 3:'happy', 4:'neutral', 5:'sad', 6:'surprise'}\n",
        "label_origin = [label_dic[x] for x in labels_list.tolist()]\n",
        "pred_origin = [label_dic[x] for x in predictions_list.tolist()]\n",
        "\n",
        "from collections import Counter\n",
        "label_counter = Counter(label_origin)\n",
        "pred_counter = Counter(pred_origin)\n",
        "\n",
        "print(\"Label:\\n\", label_counter.most_common(), end='\\n\\n')\n",
        "print(\"Pred:\\n\", pred_counter.most_common())"
      ],
      "metadata": {
        "id": "Jq1lX1lwIR_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "혼동행렬 확인"
      ],
      "metadata": {
        "id": "gWTy32mVIZU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import MulticlassConfusionMatrix\n",
        "preds = torch.tensor(predictions_list)\n",
        "target = torch.tensor(labels_list)\n",
        "confmat = MulticlassConfusionMatrix(task=\"multiclass\", num_classes=7)\n",
        "confmat(preds, target) "
      ],
      "metadata": {
        "id": "x155OKp9IYsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class별 F1 score확인"
      ],
      "metadata": {
        "id": "GZmWmkKgIku3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn  import metrics\n",
        "print(metrics.classification_report(predictions_list, labels_list))"
      ],
      "metadata": {
        "id": "UcQzgLktIc46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 평가"
      ],
      "metadata": {
        "id": "uaVFBqpLIsWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 데이터로더에 필요한 모듈 정의 및 데이터 불러오기"
      ],
      "metadata": {
        "id": "gLO9Rb3pHEzW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "def get_numpy_from_nonfixed_2d_array(data, fixed_length=141):\n",
        "    rows = []\n",
        "    for a in data:\n",
        "        rows.append(np.pad(a, (0, fixed_length), 'constant', constant_values=0)[:fixed_length])\n",
        "    return np.concatenate(rows, axis=0).reshape(-1, fixed_length)\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, file_path):\n",
        "        df = pd.read_pickle(file_path)\n",
        "\n",
        "        self.temp_array = get_numpy_from_nonfixed_2d_array(df.temp.values, fixed_length=141)\n",
        "        self.eda_array = get_numpy_from_nonfixed_2d_array(df.eda.values, fixed_length=141) \n",
        "        self.temp_ten = torch.Tensor(self.temp_array)\n",
        "        self.eda_ten = torch.Tensor(self.eda_array)\n",
        "        \n",
        "        self.train_y = df.emotion_id.values\n",
        "        self.length = len(df)\n",
        "\n",
        "        self.train_y = torch.LongTensor(self.train_y)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        t = self.temp_ten[index]\n",
        "        e = self.eda_ten[index]\n",
        "        y = self.train_y[index]\n",
        "        return t,e,y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "metadata": {
        "id": "t-BYEC1jCQrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = CustomDataset(\"./dataset/KEMDy20_v1_1/sensor/bio_train/test_origin.pkl\")\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, drop_last=False)"
      ],
      "metadata": {
        "id": "mwJHX0S-IvV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test F1 score 및 Accuracy확인"
      ],
      "metadata": {
        "id": "SOc_IV5CI_ih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import F1Score\n",
        "\n",
        "labels_list = []\n",
        "predictions_list = []\n",
        "extraction = []\n",
        "result = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for t, e, y in test_dataloader:\n",
        "      t = t.to(device)\n",
        "      e = e.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      output = model(t,e)\n",
        "      result.append(output)\n",
        "\n",
        "      labels_list.extend(y)\n",
        "      predictions = torch.max(output,1)[1].to(device)\n",
        "      predictions_list.extend(predictions)\n",
        "\n",
        "  predictions_list = torch.tensor(predictions_list)\n",
        "  labels_list = torch.tensor(labels_list)\n",
        "\n",
        "  f1 = F1Score(task='multiclass', num_classes=7)\n",
        "  f1_score = f1(predictions_list, labels_list)\n",
        "  auc = Accuracy(task='multiclass', num_classes=7)\n",
        "  auc_score = auc(predictions_list, labels_list)\n",
        "\n",
        "  print('f1:',f1_score, 'auc:',auc_score)"
      ],
      "metadata": {
        "id": "FfajpHN0CQt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class별로 예측 값 개수 확인"
      ],
      "metadata": {
        "id": "_vl9pnzDJP-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_dic = {0:'angry', 1:'disqust',2:'fear', 3:'happy', 4:'neutral', 5:'sad', 6:'surprise'}\n",
        "label_origin = [label_dic[x] for x in labels_list.tolist()]\n",
        "pred_origin = [label_dic[x] for x in predictions_list.tolist()]\n",
        "\n",
        "from collections import Counter\n",
        "label_counter = Counter(label_origin)\n",
        "pred_counter = Counter(pred_origin)\n",
        "\n",
        "print(\"Label:\\n\", label_counter.most_common(), end='\\n\\n')\n",
        "print(\"Pred:\\n\", pred_counter.most_common())"
      ],
      "metadata": {
        "id": "-FmCA3V6CQwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "혼동행렬 확인"
      ],
      "metadata": {
        "id": "OXsPOBlAJTDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import MulticlassConfusionMatrix\n",
        "preds = torch.tensor(predictions_list)\n",
        "target = torch.tensor(labels_list)\n",
        "confmat = MulticlassConfusionMatrix(task=\"multiclass\", num_classes=7)\n",
        "confmat(preds, target) "
      ],
      "metadata": {
        "id": "7kGbI8WcCQyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class별 F1 Score확인"
      ],
      "metadata": {
        "id": "mv5Br91ZJWZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn  import metrics\n",
        "print(metrics.classification_report(predictions_list, labels_list))"
      ],
      "metadata": {
        "id": "rl4h4S-tCQ1F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#앙상블을 위한 결과값 저장"
      ],
      "metadata": {
        "id": "-wtuJ2EUj9R1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측 결과 데이터 프레임으로 만들기\n",
        "pred_output = torch.cat(result, 0)\n",
        "pred_np = pred_output.detach().cpu().numpy()\n",
        "pred_df = pd.DataFrame(pred_np, columns=['angry', 'disqust','fear', 'happy', 'neutral', 'sad', 'surprise'])\n",
        "pred_df"
      ],
      "metadata": {
        "id": "dHXX4zCVkDVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# segment_id와 결합\n",
        "test_result = pd.concat([test['segment_id'],pred_df],axis=1)\n",
        "test_result"
      ],
      "metadata": {
        "id": "5I63cjsnkL6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종 결과 데이터 프레임 저장\n",
        "test_result.to_pickle(\"./dataset/KEMDy20_v1_1/sensor/result/bio_result.pkl\")"
      ],
      "metadata": {
        "id": "YEP01fd7kOIo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
