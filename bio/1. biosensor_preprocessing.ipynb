{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 생체 신호 데이터 초기 전처리"
      ],
      "metadata": {
        "id": "i6oaVPLgiVLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 바이오 데이터 합치기"
      ],
      "metadata": {
        "id": "Le-bf-kDKgEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# 세션별 저장한 바이오(eda, temo)파일 경로 지정\n",
        "eda_dir = './dataset/KEMDy20_v1_1/new/sensor/EDA'\n",
        "temp_dir = './dataset/KEMDy20_v1_1/new/sensor/Temp'\n",
        "\n",
        "# 지젇된 경로 파일 불러오기 및 정렬렬\n",
        "eda_sess_FList = sorted(os.listdir(eda_dir))\n",
        "temp_sess_FList = sorted(os.listdir(temp_dir))\n",
        "\n",
        "# 빈 데이터 프레임 만들기\n",
        "bio_all = pd.DataFrame(columns=['segment_id','eda','temp'])\n",
        "\n",
        "# 세션별 저장된 바이오(eda,temp) 데이터 합치기\n",
        "for eda, temp in zip(eda_sess_FList, temp_sess_FList):\n",
        "  print(eda, temp)\n",
        "  TEMP = pd.read_pickle('./dataset/KEMDy20_v1_1/new/sensor/Temp/'+ temp )\n",
        "  EDA = pd.read_pickle('./dataset/KEMDy20_v1_1/new/sensor/EDA/'+ eda )\n",
        "  TEMP.columns = ['segment_id','temp']\n",
        "  EDA.columns = ['segment_id','eda']\n",
        "  bio = EDA.merge(TEMP, on = 'segment_id')\n",
        "  bio_all = pd.concat([bio_all, bio], ignore_index=True)\n",
        "  bio_all"
      ],
      "metadata": {
        "id": "mK2pfv02KgN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "segment_id를 기준으로 annotation데이터와 합치기"
      ],
      "metadata": {
        "id": "Xu7W9JZagGsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리된 annotation 데이터 불러오기\n",
        "\n",
        "train = pd.read_pickle('./dataset/KEMDy20_v1_1/new/annotation/train_origin.pkl')\n",
        "test = pd.read_pickle('./dataset/KEMDy20_v1_1/new/annotation/test_origin.pkl')"
      ],
      "metadata": {
        "id": "thwSIttKgAOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotation 데이터와 segment_id 기준으로 merge\n",
        "\n",
        "bio_train = train.merge(bio_all, how = 'inner', on = 'segment_id')\n",
        "bio_test = test.merge(bio_all, how = 'inner', on = 'segment_id')"
      ],
      "metadata": {
        "id": "0CAbprpilg1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최종종 바이오 데이터 프레임 저장\n",
        "\n",
        "bio_train.to_pickle('./dataset/KEMDy20_v1_1/new/sensor/bio_train/train_origin.pkl')\n",
        "bio_test.to_pickle('./dataset/KEMDy20_v1_1/new/sensor/bio_train/test_origin.pkl')"
      ],
      "metadata": {
        "id": "lLzh4R6rlg33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터 증강 및 패딩 과정"
      ],
      "metadata": {
        "id": "wYTvVFgAhBA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "train = pd.read_pickle('./dataset/KEMDy20_v1_1/new/sensor/bio_train/train_origin.pkl') \n",
        "test = pd.read_pickle('./dataset/KEMDy20_v1_1/new/sensor/bio_train/test_origin.pkl')"
      ],
      "metadata": {
        "id": "fZhdapMzCmEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 함수\n",
        "def get_numpy_from_nonfixed_2d_array(aa, fixed_length=141):\n",
        "    rows = []\n",
        "    for a in aa:\n",
        "        rows.append(np.pad(a, (0, fixed_length), 'constant', constant_values=0)[:fixed_length])\n",
        "    return np.concatenate(rows, axis=0).reshape(-1, fixed_length)"
      ],
      "metadata": {
        "id": "eLk6Wuf_g-oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 패딩 진행\n",
        "temp = get_numpy_from_nonfixed_2d_array(train['temp'])\n",
        "eda = get_numpy_from_nonfixed_2d_array(train['eda'])\n",
        "train_y = train.emotion_id.values"
      ],
      "metadata": {
        "id": "oZ8SchhrCbqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"기쁨\" 맞춰 데이터 증강"
      ],
      "metadata": {
        "id": "cc4znl8JBBpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# padding한 array에서 \"중립\" 클래스 데이터 제외\n",
        "Temp=pd.DataFrame(temp)\n",
        "Temp['emotion']=pd.DataFrame(train_y)\n",
        "\n",
        "EDA = pd.DataFrame(eda)\n",
        "EDA['emotion']=pd.DataFrame(train_y)\n",
        "\n",
        "nedf = EDA.loc[(EDA.emotion==4),:].drop(['emotion'],axis=1).to_numpy()\n",
        "ntdf = Temp.loc[(Temp.emotion==4),:].drop(['emotion'],axis=1).to_numpy()\n",
        "n_y = Temp.loc[(Temp.emotion==4),'emotion'].to_numpy()\n",
        "\n",
        "edf = EDA.loc[(EDA.emotion!=4),:].drop(['emotion'],axis=1).to_numpy()\n",
        "tdf = Temp.loc[(Temp.emotion!=4),:].drop(['emotion'],axis=1).to_numpy()\n",
        "y =EDA.loc[(EDA.emotion!=4),'emotion'].to_numpy()"
      ],
      "metadata": {
        "id": "1fIbWIAvhIOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote = SMOTE(random_state= 1024)\n",
        "temp_x,t_y = smote.fit_resample(tdf,y)\n",
        "eda_x,t_y = smote.fit_resample(edf,y)"
      ],
      "metadata": {
        "id": "zCT5yHhTB0Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"중립\" 클래스 데이터와 합치기기\n",
        "htemp = np.concatenate((temp_x,ntdf), axis=0)\n",
        "heda = np.concatenate((eda_x,nedf), axis=0)\n",
        "h_y = np.concatenate((t_y,n_y), axis=0)"
      ],
      "metadata": {
        "id": "wZQIdDtSB2Hc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 증강한 바이오 데이터 배열 저장\n",
        "np.save('./dataset/KEMDy20_v1_1/new/sensor/bio_train/temp_x.npy',htemp)\n",
        "np.save('./dataset/KEMDy20_v1_1/new/sensor/bio_train/eda_x.npy',heda)\n",
        "np.save('./dataset/KEMDy20_v1_1/new/sensor/bio_train/t_y.npy',h_y)"
      ],
      "metadata": {
        "id": "NSBDUdIihp9I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}